= Prepare your existing environment for migration

In this topic, we'll discuss the steps you'll perform to prepare your existing cluster for migration to a new environment.

We'll use this example scenario: migration an Apache Cassandra&reg; or DataStax Enterprise (DSE) cluster to Astra DB.

Of course, your existing Cassandra or DSE cluster has database tables, populated with data, and client apps that interact in real time with the database.

[NOTE]
====
(**Alice's note:** we should briefly define the {data-migrator}, and include some advice here on the infrastructure specs for the machine(s) used to run it. This is not currently documented anywhere. Experience from the Field team will help.)
====

== {data-migrator}

{data-migrator} is designed to:

* Connect to, and compare your target database with the origin
* Report differences in a detailed log file
* Reconcile any missing records and fix any data inconsistencies in the target, if you enable `autocorrect` in a config file

For details about installing and using {data-migrator}, see xref:migration-validate-data.adoc[]. 

[TIP]
====
An important **prerequisite** is that you already have the matching schema on the target database. For every table migrated by Cassandra Data Migrator, the tool takes a mapping configuration that links every origin column to every target column. 
====

The validation checks are a way to verify that all the data has been migrated successfully.

=== Example

Consider the following example:

* Origin table: `User` with fields `id uuid, first_name text, last_name text, age int`
* Target table: `Customer` with fields `cust_id uuid, fn text, ln text, contact text`

In this example, the schema is not identical. However, mapping the fields is possible to enable the data migration. That is, map `User` to `Customer`; map `id` to `cust_id`; map `first_name` to `fn`, and so on. The data for this scenario can be migrated. You would need to first define define this mapping in the config file used by {data-migrator}.

**TODO**: In the xref:migration-validate-data.adoc[] topic, provide details on how the mapping is defined in a config file.

=== Infrastructure required on existing (origin) cluster

Refer to xref:migration-infrastructure.adoc[]. 

////

Commenting out the DSBulk Migrator section; decided to instead emphasize Cassandra Data Migrator.

. To begin, download the https://drive.google.com/file/d/179J1NLjpsbNmurxM4Wfe86v9ExIkwscu/view?usp=sharing[{company} ZDM Bulk Migrator] jar file.
. Transfer it via `scp` onto the instance where it will run:
+
```bash
scp -i <your_ssh_key> schema-migrator-1.0.0-SNAPSHOT-embedded-dsbulk.jar ubuntu@<public IP of migrator instance>:
```
. Ssh into this instance and change the permission of this jar to make it executable.
+
```bash
ssh -i <your_ssh_key> ubuntu@<public IP of migrator instance>
```
. Install the default jre:
+
```bash
sudo apt-get update
sudo apt-get install default-jre
```
. Make the jar executable:
+
```bash
chmod +x schema-migrator-1.0.0-SNAPSHOT-embedded-dsbulk.jar
```
. Verify that the ZDM Bulk Migrator was installed properly:
+
```bash
java --version
java -jar schema-migrator-1.0.0-SNAPSHOT-embedded-dsbulk.jar --version
```

////


== What's next? 

Learn how to xref:migration-create-target.adoc[Create the target environment for your migration] for your migration; in this example, we'll set up a DataStax Astra DB cloud-native database instance.