Parameters to perform schema transformations between the origin and target clusters.

By default, these parameters are commented out.

[cols="2,1,4a"]
|===
|Property | Default | Notes

| `spark.cdm.transform.missing.key.ts.replace.value`
| `1685577600000`
| Timestamp value in milliseconds. 
Partition and clustering columns cannot have null values. 
If they are added as part of a schema transformation between the origin and target clusters, it is possible that the origin side is null.
In this case, the `Migrate` data operation fails.
This parameter allows a crude constant value to be used in its place that is separate from the constant values feature.

| `spark.cdm.transform.custom.writetime` 
| `0`
| Default is 0 (disabled).
Timestamp value in microseconds to use as the `WRITETIME` for the target record.
This is useful when the `WRITETIME` of the record in the origin cluster cannot be determined. Such an example is when the only non-key columns are collections.
This parameter allows a crude constant value to be used in its place and overrides `spark.cdm.schema.origin.column.writetime.names`.

| `spark.cdm.transform.custom.writetime.incrementBy` 
| `0`
| Default is `0`.
This is useful when you have a list that is not frozen and you are updating this using the autocorrect feature.
Lists are not idempotent, and subsequent UPSERTs add duplicates to the list.

| `spark.cdm.transform.codecs` 
| 
| Default is empty.
A comma-separated list of additional codecs to enable. 

 * `INT_STRING` : int stored in a string.
 * `DOUBLE_STRING` : double stored in a string.
 * `BIGINT_STRING` : bigint stored in a string.
 * `DECIMAL_STRING` : decimal stored in a string.
 * `TIMESTAMP_STRING_MILLIS` : timestamp stored in a string, as Epoch milliseconds.
 * `TIMESTAMP_STRING_FORMAT` : timestamp stored in a string with a custom format.

[NOTE]
====
Where there are multiple type pair options, such as with `TIMESTAMP_STRING_*`, only one can be configured at a time with the `spark.cdm.transform.codecs` parameter.
====

| `spark.cdm.transform.codecs.timestamp.string.format` 
| `yyyyMMddHHmmss`
| Configuration for `CQL_TIMESTAMP_TO_STRING_FORMAT` codec.
Default format is `yyyyMMddHHmmss`; `DateTimeFormatter.ofPattern(formatString)`


| `spark.cdm.transform.codecs.timestamp.string.zone` 
| `UTC`
| Default is `UTC`.
Must be in `ZoneRulesProvider.getAvailableZoneIds()`.

|===