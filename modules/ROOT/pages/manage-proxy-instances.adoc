= Manage your {product-proxy} instances

After you deploy {product-proxy} instances, you might need to perform various management operations, such as rolling restarts, configuration changes, log inspection, version upgrades, and infrastructure changes.

If you are using {product-automation}, you can use Ansible playbooks for all of these operations.

== Perform a rolling restart of the proxies

Rolling restarts of the {product-proxy} instances are useful to apply configuration changes or to upgrade the {product-proxy} version without impacting the availability of the deployment.

[tabs]
======
With {product-automation}::
+
--
If you use {product-automation} to manage your {product-proxy} deployment, you can use a dedicated playbook to perform rolling restarts of all {product-proxy} instances in a deployment:

. Connect to the Ansible Control Host Docker container.
You can do this from the jumphost machine by running the following command:
+
[source,bash]
----
docker exec -it zdm-ansible-container bash
----
+
.Result
[%collapsible]
====
[source,bash]
----
ubuntu@52772568517c:~$
----
====

. Run the rolling restart playbook:
+
[source,bash]
----
ansible-playbook rolling_update_zdm_proxy.yml -i zdm_ansible_inventory
----
+
While running, this playbook gracefully stops one container and waits for it to shut down before restarting the container.
Then, it calls the xref:deploy-proxy-monitoring.adoc#_indications_of_success_on_origin_and_target_clusters[readiness endpoint] to check the container's status:
+
* If the check fails, the playbook repeats the check every five seconds for a maximum of six attempts.
If all six attempts fail, the playbook interrupts the entire rolling restart process.
* If the check succeeds, the playbook waits before proceeding to the next container.
+
The default pause between containers is 10 seconds.
You can change the pause duration in `zdm-proxy-automation/ansible/vars/zdm_playbook_internal_config.yml`.
--

Without {product-automation}::
+
--
If you don't use {product-automation}, you must manually restart each instance.

To avoid downtime, wait for each instance to fully restart and begin receiving traffic before restarting the next instance.
--
======

== Inspect {product-proxy} logs

{product-proxy} logs can help you verify that your {product-proxy} instances are operating normally, investigate how processes are executed, and troubleshoot issues.
For information about configuring, retrieving, and interpreting {product-proxy} logs, see xref:ROOT:troubleshooting-tips.adoc#proxy-logs[Viewing and interpreting {product-proxy} logs].

[[change-mutable-config-variable]]
== Change mutable configuration variables

Some, but not all, configuration variables can be changed after you deploy a {product-proxy} instance.

This section lists the _mutable_ configuration variables that you can change on an existing {product-proxy} deployment using the rolling restart playbook.

=== Mutable variables in `vars/zdm_proxy_core_config.yml`

* `primary_cluster`: Determines which cluster is currently considered the xref:ROOT:faqs.adoc#what-are-origin-target-primary-and-secondary-clusters[primary cluster], either `ORIGIN` or `TARGET`.
+
At the start of the migration, the primary cluster is the origin cluster because it contains all of the data.
After all the existing data has been transferred and validated/reconciled on the new cluster, you can switch the primary cluster to the target cluster.

* `read_mode`: Determines how reads are handled by {product-proxy}:
+
** `PRIMARY_ONLY` (default): Reads are sent synchronously to the primary cluster only.
** `DUAL_ASYNC_ON_SECONDARY`: Reads are sent synchronously to the primary cluster, and also asynchronously to the secondary cluster.
See xref:enable-async-dual-reads.adoc[].
+
Typically, you only set `read_mode` to `DUAL_ASYNC_ON_SECONDARY` if the `primary_cluster` variable is set to `ORIGIN`.
This is because asynchronous dual reads are primarily intended to help test production workloads against the target cluster near the end of the migration.
When you are ready to switch `primary_cluster` to `TARGET`, revert `read_mode` to `PRIMARY_ONLY` because there is no need to send writes to both clusters at that point in the migration.

* `log_level`: Set the {product-proxy} log level as `INFO` (default) or `DEBUG`.
+
Only use `DEBUG` while temporarily troubleshooting an issue.
Revert to `INFO` as soon as possible because the extra logging can impact performance slightly.
+
For more information, see xref:ROOT:troubleshooting-tips.adoc#proxy-logs[Check {product-proxy} logs].

=== Mutable variables in `vars/zdm_proxy_cluster_config.yml`

* Origin username and password

* Target username and password

=== Mutable variables in `vars/zdm_proxy_advanced_config.yml`

* `zdm_proxy_max_clients_connections`: The maximum number of client connections that {product-proxy} can accept.
Each client connection results in additional cluster connections and causes the allocation of several in-memory structures.
A high number of client connections per proxy instance can cause performance degradation, especially at high throughput.
Adjust this variable to limit the total number of connections on each instance.
+
Default: `1000`

* `replace_cql_functions`: Whether {product-proxy} replaces standard `now()` CQL function calls in write requests with an explicit timeUUID value computed at proxy level.
+
If `false` (default), replacement of `now()` is disabled.
If `true`, {product-proxy} replaces instances of `now()` in write requests with an explicit timeUUID value before sending the write to each cluster.
+
[IMPORTANT]
====
Enabling `replace_cql_functions` has a noticeable performance impact because the proxy must do more extensive parsing and manipulation of the statements before sending the modified statement to each cluster.
Only enable this variable if required, and implement proper performance testing to quantify and prepare for the performance impact.

If you use `now()` to populate a regular (non-primary key) column, consider if you can pragmatically accept a slight discrepancy in the values between the origin and target cluster for these writes.
This depends on your application, and whether it can tolerate a potential difference of a few milliseconds.

However, if you use `now()` to populate a primary key column, differences between the origin and target values result in different primary keys.
This means that the same row on the origin and target are technically considered different records, and this will cause problems with duplicate entries that aren't caught by validation (because the primary keys are different).
If `now()` is used in any of your primary key columns, {company} recommends enabling `replace_cql_functions`, regardless of the performance impact.

For more information, see xref:ROOT:feasibility-checklists.adoc#cql-function-replacement[Server-side non-deterministic functions in the primary key].
====

* `zdm_proxy_request_timeout_ms`: Global timeout in milliseconds of a request at proxy level.
Determines how long {product-proxy} waits for one cluster (for reads) or both clusters (for writes) to reply to a request.
Upon reaching the timeout limit, {product-proxy} abandons the request and no longer considers it pending, which frees up internal resources to processes other requests.
When a request is abandoned due to a timeout, {product-proxy} doesn't return any result or error.
A timeout warning or error is only returned when the client application's own timeout is reached and the request is expired on the driver side.
+
Make sure `zdm_proxy_request_timeout_ms` is always greater than your client application's client-side timeout.
If the client has an especially high timeout because it routinely generates long-running requests, you must increase the `zdm_proxy_request_timeout_ms` timeout accordingly so that the {product-proxy} doesn't abandon requests prematurely.
+
Default: `10000`

* `origin_connection_timeout_ms` and `target_connection_timeout_ms`: Timeout in milliseconds for establishing a connection from the proxy to the origin or target cluster, respectively.
+
Default: `30000`

* `async_handshake_timeout_ms`: Timeout in milliseconds for the initialization (handshake) of the connection that is used solely for asynchronous dual reads between the proxy and the secondary cluster.
+
Upon reaching the timeout limit, the asynchronous reads aren't sent because the connection failed to be established.
This has no impact on the handling of synchronous requests: {product-proxy} continues to handle all synchronous reads and writes as normal against the primary cluster.
+
Default: `4000`

* `heartbeat_interval_ms`: The interval in milliseconds that heartbeats are sent to keep idle cluster connections alive.
This includes all control and request connections to the origin and the target clusters.
+
Default: `30000`

* `metrics_enabled`: Whether to enable metrics collection.
The default is `true` (enabled).
+
If `false`, {product-proxy} metrics collection is completely disabled.
This isn't recommended.

[[zdm_proxy_max_stream_ids]]
* `zdm_proxy_max_stream_ids`: Set the maximum pool size of available stream IDs managed by {product-proxy} per client connection.
Use the same value as your driver's maximum stream IDs configuration.
+
In the CQL protocol, every request has a unique stream ID.
However, if there are a lot of requests in a given amount of time, errors can occur due to xref:datastax-drivers:developing:speculative-retry.adoc#stream-id-exhaustion[stream ID exhaustion].
+
In the client application, the stream IDs are managed internally by the driver, and, in most drivers, the max number is 2048, which is the same default value used by {product-proxy}.
If you have a custom driver configuration with a higher value, make sure `zdm_proxy_max_stream_ids` matches your driver's maximum stream IDs.
+
Defaults: `2048`

=== Deprecated mutable variables

Deprecated variables will be removed in a future {product-proxy} release.
Replace them with their recommended alternatives as soon as possible.

* `forward_client_credentials_to_origin`: Whether to use the credentials provided by the client application to connect to the origin cluster.
If `false` (default), the credentials from the client application were used to connect to the target cluster.
If `true`, the credentials from the client application were used to connect to the origin cluster.
+
This deprecated variable is no longer functional.
Instead, the expected credentials are based on the authentication requirements of the origin and target clusters.
For more information, see xref:ROOT:connect-clients-to-proxy.adoc#_client_application_credentials[Client application credentials].

=== Apply mutable configuration changes

Edit mutable variables in their corresponding configuration files (`vars/zdm_proxy_core_config.yml`, `vars/zdm_proxy_cluster_config.yml`, or `vars/zdm_proxy_advanced_config.yml`), and then apply the configuration changes to your {product-proxy} instances using the rolling restart playbook.

[IMPORTANT]
====
A configuration change is a destructive action because the rolling restart playbook removes the previous containers and their logs, replacing them with new containers and the new configuration.
xref:ROOT:troubleshooting-tips.adoc#proxy-logs[Collect the logs] before you run the playbook if you want to keep them.
====

[source,bash]
----
ansible-playbook rolling_update_zdm_proxy.yml -i zdm_ansible_inventory
----

The rolling restart playbook recreates each {product-proxy} container, one by one, with the updated configuration files.
The {product-proxy} deployment remains available at all times, and you can safely use it throughout this operation.

The playbook performs the following actions automatically:

. {product-automation} stops one container gracefully, and then waits for it to shut down.
. {product-automation} recreates the container, and then starts it.
. {product-automation} checks that the container started successfully by checking the readiness endpoint:
+
* If unsuccessful, {product-automation} repeats the check up to six times at 5-second intervals.
If it still fails, {product-automation} interrupts the entire rolling restart process.
* If successful, {product-automation} waits 10 seconds (default), and then moves on to the next container.
+
The pause between the restart of each {product-proxy} instance defaults to 10 seconds.
To change this value, you can set the desired number of seconds in `zdm-proxy-automation/ansible/vars/zdm_playbook_internal_config.yml`.

== Change immutable configuration variables

All configuration variables not listed in <<change-mutable-config-variable>> are _immutable_ and can only be changed by recreating the deployment with the xref:ROOT:deploy-proxy-monitoring.adoc[initial deployment playbook] (`deploy_zdm_proxy.yml`).

You can re-run the deployment playbook as many times as necessary.
However, this playbook decommissions and recreates _all_ {product-proxy} instances simultaneously.
This results in a brief period of time where the entire {product-proxy} deployment is offline because no instances are available.

For more information, see xref:ROOT:troubleshooting-tips.adoc#configuration-changes-arent-applied-by-zdm-automation[Configuration changes aren't applied by {product-automation}].

[[_upgrade_the_proxy_version]]
== Upgrade the proxy version

The same playbook that you use for configuration changes can also be used to upgrade the {product-proxy} version in a rolling fashion.
All containers are recreated with the given image version.

[IMPORTANT]
====
A version change is a destructive action because the rolling restart playbook removes the previous containers and their logs, replacing them with new containers using the new image.
xref:ROOT:troubleshooting-tips.adoc#proxy-logs[Collect the logs] before you run the playbook if you want to keep them.
====

To check your current {product-proxy} version, see xref:ROOT:troubleshooting-tips.adoc#check-version[Check your {product-proxy} version].

. In `vars/zdm_proxy_container.yml`, set `zdm_proxy_image` to the desired tag.
For available tags, see the https://hub.docker.com/r/datastax/zdm-proxy/tags[{product-proxy} Docker Hub repository].
+
[source,yaml,subs="+quotes"]
----
zdm_proxy_image: datastax/zdm-proxy:**TAG**
----
+
For example:
+
[source,yaml]
----
zdm_proxy_image: datastax/zdm-proxy:2.3.4
----

. Run the `rolling_update_zdm_proxy.yml` playbook:
+
[source,bash]
----
ansible-playbook rolling_update_zdm_proxy.yml -i zdm_ansible_inventory
----
+
The rolling restart playbook recreates each {product-proxy} container, one by one, with the new image.
The {product-proxy} deployment remains available at all times, and you can safely use it throughout this operation.
+
The playbook performs the following actions automatically:
+
.. {product-automation} stops one container gracefully, and then waits for it to shut down.
.. {product-automation} recreates the container, and then starts it.
.. {product-automation} checks that the container started successfully by checking the readiness endpoint:
+
** If unsuccessful, {product-automation} repeats the check up to six times at 5-second intervals.
If it still fails, {product-automation} interrupts the entire rolling restart process.
** If successful, {product-automation} waits 10 seconds (default), and then moves on to the next container.
+
The pause between the restart of each {product-proxy} instance defaults to 10 seconds.
To change this value, you can set the desired number of seconds in `zdm-proxy-automation/ansible/vars/zdm_playbook_internal_config.yml`.

== Scale {product-proxy} instances

[tabs]
======
Scale with {product-automation}::
+
--
{product-automation} doesn't provide a way to scale operations up or down in a rolling fashion.
If you are using {product-automation} and you need a larger {product-proxy} deployment, you can create a new deployment, or you can add instances to an existing deployment.

[tabs]
====
Create a new deployment (recommended)::
+
This option is the recommended way to scale your {product-proxy} deployment because it requires no downtime.
+
Create a new {product-proxy} deployment, and then reconfigure your client application to use the new instance:
+
. xref:ROOT:setup-ansible-playbooks.adoc[Create a new {product-proxy} deployment] with the desired topology on a new set of machines.
. Change the contact points in the application configuration so that the application instances point to the new {product-proxy} deployment.
. Perform a rolling restart of the application instances to apply the new contact point configuration.
+
The rolling restart ensures there is no interruption of service.
The application instances switch seamlessly from the old deployment to the new one, and they are able to serve requests immediately.
. After restarting all application instances, you can safely remove the old {product-proxy} deployment.

Add instances to an existing deployment::
+
This option requires manual configuration and a small amount of downtime.
+
Change the topology of your existing {product-proxy} deployment, and then restart the entire deployment to apply the change:
+
. Amend the inventory file so that it contains one line for each machine where you want to deploy a {product-proxy} instance.
+
For example, if you want to add three nodes to a deployment with six nodes, then the amended inventory file must contain nine total IPs, including the six existing IPs and the three new IPs.
+
. Run the `deploy_zdm_proxy.yml` playbook to apply the change and start the new instances.
+
Rerunning the playbook stops the existing instances, destroys them, and then creates and starts a new deployment with new instances based on the amended inventory.
This results in a brief interruption of service for your entire {product-proxy} deployment.
====
--

Scale without {product-automation}::
+
--
If you aren't using {product-automation}, use these steps to add, change, or remove {product-proxy} instances.

[tabs]
====
Add an instance::
+
. Prepare and configure the new {product-proxy} instances appropriately based on your other instances.
+
Make sure the new instance's configuration references all planned {product-proxy} cluster nodes.
+
. On all {product-proxy} instances, add the new instance's address to the `ZDM_PROXY_TOPOLOGY_ADDRESSES` environment variable.
+
Make sure to include all new nodes.
+
. On the new {product-proxy} instance, set the `ZDM_PROXY_TOPOLOGY_INDEX` to the next sequential integer after the greatest one in your existing deployment.
+
. Perform a rolling restart of all {product-proxy} instances, one at a time.

Vertically scale existing instances::
+
Use these steps to increase or decrease resources for existing {product-proxy} instances, such as CPU or memory.
To avoid downtime, perform the following steps on one instance at a time:
+
. Stop the first {product-proxy} instance that you want to modify.
+
. Modify the instance's resources as required.
+
Make sure the instance's IP address remains the same.
If the IP address changes, you must treat it as a new instance; follow the steps on the **Add an instance** tab.
+
. Restart the modified {product-proxy} instance.
+
. Wait until the instance starts, and then confirm that it is receiving traffic.
+
. Repeat these steps to modify each additional instance, one at a time.

Remove an instance::
+
. On all {product-proxy} instances, remove the unused instance's address from the `ZDM_PROXY_TOPOLOGY_ADDRESSES` environment variable.
. Perform a rolling restart of all remaining {product-proxy} instances.
. Clean up resources used by the removed instance, such as the container or VM.
====
--
======

=== Proxy topology addresses enable failover and high availability

When you configure a {product-proxy} deployment, either through {product-automation} or manually-managed {product-proxy} instances, you specify the addresses of your instances.
These are populated in the `ZDM_PROXY_TOPOLOGY_ADDRESSES` variable, either manually or automatically depending on how you manage your instances.

{cass-short} drivers look up nodes on a cluster by querying the `system.peers` table.
{product-proxy} uses the topology addresses to effectively respond to the driver's request for connection nodes.
If there are no topology addresses specified, {product-proxy} defaults to a single-instance configuration.
This means that driver connections use only that one {product-proxy} instance rather than all instances in your {product-proxy} deployment.

If that one instance goes down, {product-proxy} won't know that there are other instances available, and your application can experience an outage.
Additionally, if you need to restart {product-proxy} instances, and there is only one instance specified in the topology addresses, your migration will have downtime while that one instance restarts.

== See also

* xref:ROOT:troubleshooting-tips.adoc[]
* xref:deploy-proxy-monitoring.adoc#_indications_of_success_on_origin_and_target_clusters[Indications of success on origin and target clusters]