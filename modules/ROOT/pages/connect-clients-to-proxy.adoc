= Connect your client applications to {product-proxy}
:navtitle: Connect client applications to {product-proxy}
:page-tag: migration,zdm,zero-downtime,zdm-proxy,connect-apps

The {product-proxy} is designed to be similar to a conventional {cass-reg} cluster.
You communicate with it using the CQL query language used in your existing client applications.
It understands the same messaging protocols used by {cass-short}, {dse}, and {astra-db}.
As a result, most of your client applications won't be able to distinguish between connecting to {product-proxy} and connecting directly to your {cass-short} cluster.

On this page, we explain how to connect your client applications to a {cass-short} cluster.
We then move on to discuss how this process changes when connecting to a {product-proxy}.
We conclude by describing two sample client applications that serve as real-world examples of how to build a client application that works effectively with {product-proxy}.

You can use the provided sample client applications, in addition to your own, as a quick way to validate that the deployed {product-proxy} is reading and writing data from the expected origin and target clusters.

Finally, we will explain how to connect the `cqlsh` command-line client to the {product-proxy}.

== {company}-compatible drivers

You can use {cass-short} drivers to connect your client applications to {cass-short}, {dse-short}, {hcd-short}, and {astra-db}.
With drivers, you can allow execute queries, iterate through results, access metadata about your cluster, and perform other related activities.

For available drivers and driver documentation, see xref:datastax-drivers:compatibility:driver-matrix.adoc[].

[[_connecting_company_drivers_to_cassandra]]
== Connect drivers to {cass-short}

Perhaps the simplest way to demonstrate how to use the drivers to connect your client application to a {cass-short} cluster is an example in the form of some sample code.
But there's a bit of a problem: the drivers are independent projects implemented natively in the relevant programming language.

This approach offers the benefit of allowing each project to provide an API that makes the most sense for the language or platform on which it's implemented.
Unfortunately it also means there is some variation between languages.
With that in mind, the following pseudocode provides reasonable guidance for understanding how a client application might use one of the drivers.

[source]
----
// Create an object to represent a Cassandra cluster listening for connections at
// 10.20.30.40 on the default port (9042).  The username and password are necessary
// only if your Cassandra cluster has authentication enabled.
Cluster my_cluster = Cluster.build_new_cluster(contact_points = "10.20.30.40", username="myusername", password="mypassword")

// Connect our Cluster object to our Cassandra cluster, returning a Session
Session my_session = my_cluster.connect()

// Execute a query, returning a ResultSet
ResultSet my_result_set = my_session.execute("select release_version from system.local")

// Retrieve the "release_version" column from the first row of our result set
String release_version = my_result_set.first_row().get_column("release_version")

// Close our Session and Cluster
my_session.close()
my_cluster.close()

// Display the release version to the user
print(release_version)
----

As noted, you'll see some differences in individual drivers:

* New versions of the Java driver no longer define a Cluster object.
Client programs create a Session directly.
* The Node.js driver has no notion of a Cluster or Session at all, instead using a Client object to represent this functionality.

The details may vary but you'll still see the same general pattern described in the pseudocode in each of the drivers.

This topic does not describe details or APIs for any of the drivers mentioned above.
All the drivers come with a complete set of documentation for exactly this task.
The following links provide some good starting points for learning about the interfaces for each specific driver:

//TODO: Move this to the driver docs and replace this whole list with a link to the connect page.
* The https://docs.datastax.com/en/developer/java-driver/latest/manual/core/[core driver section] of the Java driver manual.
* The https://docs.datastax.com/en/developer/python-driver/latest/getting_started/[getting started guide] for the Python driver.
* The https://docs.datastax.com/en/developer/csharp-driver/latest/index.html#basic-usage[basic usage section] of the C# driver documentation.
* The https://docs.datastax.com/en/developer/cpp-driver/latest/topics/[getting started section] of the C/C++ driver documentation.
* The https://docs.datastax.com/en/developer/nodejs-driver/latest/#basic-usage[basic usage section] of the Node.js driver documentation.

== Connect drivers to {product-proxy}

We mentioned above that connecting to a {product-proxy} should be almost indistinguishable from connecting directly to your {cass-short} cluster.
This design decision means there isn't much to say here; everything we discussed in the section above also applies when connecting your driver to {product-proxy}.
There are a few extra considerations to keep in mind, though, when using the proxy.

=== Client-side compression
Client applications must not enable client-side compression when connecting through the {product-proxy}, as this is not currently supported.
This is disabled by default in all drivers, but if it was enabled in your client application configuration it will have to be temporarily disabled when connecting to the {product-proxy}.

[[_client_application_credentials]]
=== Client application credentials

The credentials provided by the client application are used when forwarding its requests.
However, the client application has no notion that there are two clusters involved: from its point of view, it talks to just one cluster as usual.
For this reason, the {product-proxy} will only use the client application credentials when forwarding requests to one cluster (typically the target), and it will resort to using the credentials in its own configuration to forward requests to the other cluster (typically the origin).

This means that, if your {product-proxy} is configured with an origin or target cluster with **user authentication enabled**, your client application has to provide credentials when connecting to the proxy:

* If both clusters require authentication, your client application must pass the credentials for the target.
This is also the case if authentication is required by the target only, but not the origin.
* If the origin requires authentication but the target does not, then your client application must supply credentials for the origin.
* If neither cluster requires authentication, no credentials are needed.

[cols="1,1,1"]
|===
|Auth enabled on the origin
|Auth enabled on the target
|Client application credentials

|Yes
|Yes
|Target

|No
|Yes
|Target

|Yes
|No
|Origin

|No
|No
|No credentials

|===

.How different sets of credentials are used by the {product-proxy} when authentication is enabled on both clusters
image::zdm-proxy-credential-usage.png[{product-proxy} credentials usage, 550]

=== {astra-db} credentials

If your {product-proxy} is configured to use {astra-db} as the origin or target cluster, then your client application doesn't need to provide a {scb} when connecting to the proxy.

As an alternative to providing the {scb-short} directly, you can xref:astra-db-serverless:administration:manage-application-tokens.adoc[generate an application token] with the *Organization Administrator* role, and then specify one of the following sets of credentials generated with the token:

* Token-only authentication: Set `username` to the literal string `token`, and set `password` to your {astra-db} application token.
* Client ID and secret authentication (legacy): Set `username` to the `clientId` generated with your application token, and then set `password` to the `secret` generated with your application token.

== Sample client applications

[IMPORTANT]
====
These sample applications are for demonstration purposes only.
They are not intended for production use.
====

The following sample client applications demonstrate how to use the Java driver with {product-proxy} and the origin and target for that proxy.

See your driver's documentation for code samples that are specific to your chosen driver, including cluster connection examples and statement execution examples.

=== {product-demo}

https://github.com/alicel/zdm-demo-client/[{product-demo}] is a minimal Java web application which provides a simple, stripped-down example of an application built to work with {product-proxy}.
After updating connection information you can compile and run the application locally and interact with it using HTTP clients such as `curl` or `wget`.

You can find the details of building and running {product-demo} in the https://github.com/alicel/zdm-demo-client/blob/master/README.md[README].

[[_themis_client]]
=== Themis client

https://github.com/absurdfarce/themis[Themis] is a Java command-line client application that allows you to insert randomly generated data into some combination of these three sources:

* Directly into the origin
* Directly into the target
* Into the {product-proxy}, and subsequently on to the origin and target

The client application can then be used to query the inserted data.
This allows you to validate that the {product-proxy} is reading and writing data from the expected sources.
Configuration details for the clusters and/or {product-proxy} are defined in a YAML file.
Details are in the https://github.com/absurdfarce/themis/blob/main/README.md[README].

In addition to any utility as a validation tool, Themis also serves as an example of a larger client application which uses the Java driver to connect to a {product-proxy} -- as well as directly to {cass-short} clusters or {astra-db} -- and perform operations.
The configuration logic as well as the cluster and session management code have been cleanly separated into distinct packages to make them easy to understand.

== Connecting CQLSH to the {product-proxy}

https://downloads.datastax.com/#cqlsh[CQLSH] is a simple, command-line client that is able to connect to any CQL cluster, enabling you to interactively send CQL requests to it.
CQLSH comes pre-installed on any {cass-short} or {dse-short} node, or it can be downloaded and run as a standalone client on any machine able to connect to the desired cluster.

Using CQLSH to connect to a {product-proxy} instance is very easy:

* Download CQLSH for free from https://downloads.datastax.com/#cqlsh[here] on a machine that has connectivity to the {product-proxy} instances:
** To connect to the {product-proxy}, any version is fine.
** The {astra}-compatible version additionally supports connecting directly to an {astra-db} cluster by passing the cluster's {scb-short} and valid credentials.
* Install it by uncompressing the archive: `tar -xvf cqlsh-<...>.tar.gz`.
* Navigate to the `cqlsh-<...>/bin` directory, for example `cd cqlsh-astra/bin`.
* Launch CQLSH:
** Specify the IP of a {product-proxy} instance.
** Specify the port on which the {product-proxy} listens for client connections, if different to `9042`.
** Use the appropriate credentials for the {product-proxy}, as explained xref:_client_application_credentials[above].

For example, if one of your {product-proxy} instances has IP Address `172.18.10.34` and listens on port `14002`, the command would look like:
[source,bash]
----
./cqlsh 172.18.10.34 14002 -u <my_creds_user> -p <my_creds_password>
----

If the {product-proxy} listens on port `9042`, you can omit the port from the command above.
If credentials are not required, just omit the `-u` and `-p` options.