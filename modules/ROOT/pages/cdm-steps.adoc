= Migrate {cstar-data-migrator}

Use {cstar-data-migrator} to migrate and validate tables between Origin and Target Cassandra clusters, with available logging and reconciliation support.

== {cstar-data-migrator} steps

. Configure for your environment the `cdm*.properties` file that's provided in the {cstar-data-migrator} https://github.com/datastax/cassandra-data-migrator/tree/main/src/resources[GitHub repo].
The file can have any name.
It does not need to be `cdm.properties` or `cdm-detailed.properties`.
In both versions, the `spark-submit` job processes only the parameters that aren't commented out.
Other parameter values use defaults or are ignored.
See the descriptions and defaults in each file.
Refer to:
   * The simplified sample properties configuration, https://github.com/datastax/cassandra-data-migrator/blob/main/src/resources/cdm.properties[cdm.properties].
   This file contains only those parameters that are commonly configured.
   * The complete sample properties configuration, https://github.com/datastax/cassandra-data-migrator/blob/main/src/resources/cdm-detailed.properties[cdm-detailed.properties], for the full set of configurable settings.

. Place the properties file that you elected to use and customize where it can be accessed while running the job using `spark-submit`.

. Run the job using `spark-submit` command:

[source,bash]
----
./spark-submit --properties-file cdm.properties \
--conf spark.cdm.schema.origin.keyspaceTable="<keyspacename>.<tablename>" \
--master "local[*]" --driver-memory 25G --executor-memory 25G \
--class com.datastax.cdm.job.Migrate cassandra-data-migrator-x.y.z.jar &> logfile_name_$(date +%Y%m%d_%H_%M).txt
----

[TIP]
====
* Above command generates a log file `logfile_name_*.txt` to avoid log output on the console.
* Update the memory options (driver & executor memory) based on your use-case
====

[[cdm-validation-steps]]
== {cstar-data-migrator} steps in validation mode

To run your migration job with {cstar-data-migrator} in **data validation mode**, use class option `--class com.datastax.cdm.job.DiffData`. 
Example:

[source,bash]
----
./spark-submit --properties-file cdm.properties \
--conf spark.cdm.schema.origin.keyspaceTable="<keyspacename>.<tablename>" \
--master "local[*]" --driver-memory 25G --executor-memory 25G \
--class com.datastax.cdm.job.DiffData cassandra-data-migrator-x.y.z.jar &> logfile_name_$(date +%Y%m%d_%H_%M).txt
----

The {cstar-data-migrator} validation job reports differences as `ERROR` entries in the log file. 
Example:

[source,bash]
----
23/04/06 08:43:06 ERROR DiffJobSession: Mismatch row found for key: [key3] Mismatch: Target Index: 1 Origin: valueC Target: value999) 
23/04/06 08:43:06 ERROR DiffJobSession: Corrected mismatch row in target: [key3]
23/04/06 08:43:06 ERROR DiffJobSession: Missing target row found for key: [key2]
23/04/06 08:43:06 ERROR DiffJobSession: Inserted missing row in target: [key2]
----

[TIP]
====
To get the list of missing or mismatched records, grep for all `ERROR` entries in the log files.
Differences noted in the log file are listed by primary-key values.
====

You can also run the {cstar-data-migrator} validation job in an **AutoCorrect** mode. This mode can:

* Add any missing records from Origin to Target.
* Update any mismatched records between Origin and Target; this action makes Target the same as Origin.

To enable or disable this feature, use one or both of the following settings in your `*.properties` configuration file.

[source,properties]
----
spark.cdm.autocorrect.missing                     false|true
spark.cdm.autocorrect.mismatch                    false|true
----

[IMPORTANT]
====
The {cstar-data-migrator} validation job nevers delete records from Target.
The job only adds or updates data on Target.
====

[[cdm-guardrail-checks]]
== Perform large-field guardrail violation checks

Use {cstar-data-migrator} to identify large fields from a table that may break your https://docs.datastax.com/en/astra-db-serverless/cql/cassandra-guardrails.html[cluster guardrails].
For example, {astra_db} has a 10MB limit for a single large field.
Specify `--class com.datastax.cdm.job.GuardrailCheck` on the command.
Example:

[source,bash]
----
./spark-submit --properties-file cdm.properties \
--conf spark.cdm.schema.origin.keyspaceTable="<keyspacename>.<tablename>" \
--conf spark.cdm.feature.guardrail.colSizeInKB=10000 \
--master "local[*]" --driver-memory 25G --executor-memory 25G \
--class com.datastax.cdm.job.GuardrailCheck cassandra-data-migrator-4.x.x.jar &> logfile_name_$(date +%Y%m%d_%H_%M).txt
----
