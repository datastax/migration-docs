= {product} frequently asked questions
:navtitle: {product-short} FAQs
:page-aliases: ROOT:contributions.adoc, ROOT:glossary.adoc

This page includes common questions about the {company} {product} ({product-short}) tools.

== What is a zero-downtime migration?

A zero-downtime migration with the {company} {product-short} tools means you can reliably migrate your client applications and data between CQL clusters with no interruption of service.

== Which platforms and versions are supported by the {product-short} tools?

See xref:ROOT:zdm-proxy-migration-paths.adoc[].

== Why should I use the {product-short} tools for my migration?

There are several benefits to using the {product-short} tools for your migration:

Minimal client code changes::
Depending on cluster compatibility, the {product-short} tools help you migrate to a new or upgraded database platform with minimal changes to your client application code.
In some cases, you only need to change the connection string to point to the new cluster at the end of the migration process.
Typically, these changes are minimal and non-invasive, especially if your client application uses an externalized property configuration for contact points.

Real-time data consistency::
{product-proxy} orchestrates real-time activity generated by your client applications, ensuring data consistency while you replicate, validate, and test your existing data on the new cluster.
Once you set up {product-proxy}, the dual-writes feature ensures that new writes are sent to both the origin and target clusters, so you can focus on migrating the data that was present before initializing {product-proxy}.

Safely test the new cluster under full production workloads::
In addition to the dual-writes feature, you can optionally enable asynchronous dual-reads to test the target cluster's ability to handle a production workload before you permanently switch to the target cluster at the end of the migration process.
+
Client applications aren't interrupted by read errors or latency spikes on the new, target cluster.
Although these errors and metrics are received by {product-proxy} for monitoring and performance benchmarking purposes, they aren't propagated back to the client applications.
+
From the client side, traffic is seamless and uninterrupted during the entire migration process.

Seamless rollback without data loss::
If there is a problem during the migration, you can xref:ROOT:rollback.adoc[rollback to the original cluster] without any data loss or interruption of service.
You can allow {product-proxy} to continue orchestrating dual-writes, or redirect your client applications back to the origin cluster and disable {product-proxy}.

Endless validation and testing time::
Because your client applications remain fully operational during the migration, and your clusters are kept in sync by {product-proxy}, you can take as much time as you need to validate and test the target cluster before switching over permanently.

Migrate to a different platform or perform major version upgrades::
The {product-short} tools support migrations between different CQL-based platforms, such as open-source {cass-reg} to {astra-db}, as well as major version upgrades of the same platform, such as {dse-short} 5.0 to {dse-short} 6.9.

== What are the requirements for true zero-downtime migrations?

See xref:ROOT:feasibility-checklists.adoc[].

== Is there a summary of the migration process?

Yes, see xref:ROOT:introduction.adoc[].

== Is there a {product-short} demo?

Yes, you can use the xref:ROOT:introduction.adoc#lab[{product-short} interactive lab] to see how the migration process works.

== What {product-short} tools are available?

The {product-short} tools are {product-proxy}, {product-utility}, and {product-automation}.
These tools orchestrate the traffic between your client applications and the origin and target clusters during the migration process.

For the actual data migration, there are many tools you can use, such as {sstable-sideloader}, {cass-migrator}, {dsbulk-migrator}, and custom data migration scripts.

For more information, see xref:ROOT:components.adoc[].

== What is {product-proxy}?

Generally speaking, a proxy is a software class functioning as an interface to any other component, connection, or resource, such as a network connection, a server, a large object in memory, or a file.
The proxy is a wrapper or agent object that the client calls to access the real object served through that proxy.

In the context of {product-short}, the {product-proxy} is an open-source component designed to seamlessly handle real-time client application activity while a migration is in progress.
For more information, see xref:ROOT:components.adoc[].

== What are {product-automation} and {product-utility}?

{product-automation} is an Ansible-based tool that allows you to deploy and manage multiple {product-proxy} instances and the associated monitoring stack.
To simplify the setup, the {product-automation} suite includes {product-utility}, which is an interactive utility that creates a Docker container to act as the Ansible Control Host.
For more information, see xref:ROOT:components.adoc[].

== Does the {product-short} process migrate clusters?

The {product-short} process doesn't directly migrate clusters.
Instead, the {product-short} tools orchestrate live traffic between your existing cluster and a new cluster while you use a data migration tool to replicate and validate data on the new cluster.

{product-proxy} handles real-time requests generated by your client applications during the migration process, and keeps both clusters in sync through dual writes.
If there is a problem during the migration, you can confidently rollback to the original cluster without data loss or interruption of service.

At the end of the migration process, your client application connects exclusively to your new cluster, and then you decommission {product-proxy} and the old cluster.

== What challenges does {product-short} solve?

Before the {product-short} tools were available, migrating client applications between clusters involved granular and intrusive client application code changes, extensive migration preparation, and a window of downtime for the client application's end users.

With the {product-short} tools, you can migrate your client applications and data between CQL clusters with minimal code changes and no interruption of service.
You can have the confidence that you are using tools designed specifically to handle the complexities of live traffic during large enterprise migrations.

== What is the pricing model?

{product-proxy}, {product-utility}, {product-automation}, {cass-migrator}, and {dsbulk-migrator} are free and open-sourced.

{sstable-sideloader} is part of an {astra-db} *Enterprise* subscription plan, and it incurs costs based on usage.

== Where can I get help with my migration?

Technical assistance with the {product-short} process is available from {support-url}[{company} Support] for {dse-short} users, https://www.ibm.com/docs/en/esfac[IBM Elite Support for {cass}] subscribers, and {astra} organizations on an **Enterprise** plan.

For any observed problems with {product-proxy} or the other open-source {product-short} and data migration tools, you can report an issue in their respective GitHub repositories:

* {product-proxy-repo}[{product-proxy} repository]
* {product-automation-repo}[{product-automation} repository] (includes {product-automation} and {product-utility})
* {cass-migrator-repo}[{cass-migrator} repository]
* {dsbulk-migrator-repo}[{dsbulk-migrator} repository]

== Can I contribute to {product-proxy}?

Yes, see `https://github.com/datastax/zdm-proxy/blob/main/CONTRIBUTING.md[CONTRIBUTING.md]`.

== Does {product-proxy} support Transport Layer Security (TLS)?

Yes, see xref:ROOT:deploy-proxy-monitoring.adoc#enable-tls-encryption[Enable TLS encryption].

== How does {product-proxy} handle Lightweight Transactions (LWTs)?

See xref:feasibility-checklists.adoc#_lightweight_transactions_and_the_applied_flag[Lightweight Transactions and the applied flag].

== Can {product-proxy} be deployed as a sidecar?

Don't deploy {product-proxy} as a sidecar.
For more information, see xref:deployment-infrastructure.adoc#_choosing_where_to_deploy_the_proxy[Choosing where to deploy the proxy].

[#what-are-origin-target-primary-and-secondary-clusters]
== What are origin, target, primary, and secondary clusters?

These terms refer to where your data is located during the migration process, and where read and write requests are sent by {product-proxy}:

Origin and target::
The _origin cluster_ is your existing database that you are migrating away from.
The _target cluster_ is your new database that you are migrating to.
+
Origin and target cluster credentials are provided to {product-proxy} so it can establish connections and send requests to both clusters.

Primary and secondary::
The _primary cluster_ is the database that is designated as the source of truth for read requests.
It receives all read requests by default, and the responses from these read requests are returned to the client application.
The primary cluster is set by {product-automation} through the `primary_cluster` variable, or you can set it directly through the {product-proxy} `ZDM_PRIMARY_CLUSTER` environment variable.
+
The other database is the _secondary cluster_.
It doesn't receive read requests unless you enable asynchronous dual-reads.
+
For the majority of the migration process, the origin cluster is the primary cluster, and the target cluster is the secondary cluster.
Near the end of the migration, when you have validated that all pre-existing data has been replicated to the target cluster, you set the target cluster as the primary cluster.
+
Throughout the entire migration, until you decommission {product-proxy}, both clusters receive all write requests through the dual writes feature.
For more information, see xref:components.adoc#how-zdm-proxy-handles-reads-and-writes[How {product-proxy} handles reads and writes].

== Is there a difference between cluster and database?

In the context of the {product-short} process, the terms _cluster_ and _database_ are used interchangeably to refer to the source and destination for the data that you are moving during your migration.

== See also

* https://github.com/datastax/zdm-proxy/blob/main/faq.md[{product-proxy} FAQ on GitHub]