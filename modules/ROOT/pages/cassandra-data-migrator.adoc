= {cstar-data-migrator}

Use {cstar-data-migrator} to migrate and validate tables between Origin and Target Cassandra clusters, with available logging and reconciliation support.

[[cdm-prereqs]]
== {cstar-data-migrator} prerequisites

* Install or switch to Java 11.
The Spark binaries are compiled with this version of Java.
* Install https://archive.apache.org/dist/spark/spark-3.5.1/[Spark 3.5.1] on a single VM (no cluster necessary) where you want to run this job.
* Optionally, install https://maven.apache.org/download.cgi[Maven] 3.9.x if you want to build the JAR for local development.

You can install Apache Spark by running the following commands:

[source,bash]
----
wget https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3-scala2.13.tgz

tar -xvzf spark-3.5.1-bin-hadoop3-scala2.13.tgz
----

[[cdm-install-as-container]]
== Install {cstar-data-migrator} as a Container

Get the latest image that includes all dependencies from https://hub.docker.com/r/datastax/cassandra-data-migrator[DockerHub].

All migration tools (`cassandra-data-migrator` + `dsbulk` + `cqlsh`) are available in the `/assets/` folder of the container.

[[cdm-install-as-jar]]
== Install {cstar-data-migrator} as a JAR file

Download the *latest* JAR file from the {cstar-data-migrator} https://github.com/datastax/cassandra-data-migrator/packages/1832128[GitHub repo].
image:https://img.shields.io/github/v/release/datastax/cassandra-data-migrator?color=green[Latest release]

[NOTE]
====
Version 4.x of {cstar-data-migrator} is not backward-compatible with `*.properties` files created in previous versions, and package names have changed.
If you're starting new, we recommended that you use the latest released version.
====

[[cdm-build-jar-local]]
== Build {cstar-data-migrator} JAR for local development (optional)

Optionally, you can build the {cstar-data-migrator} JAR for local development. (You'll need https://maven.apache.org/download.cgi[Maven] 3.9.x.)

Example:

[source,bash]
----
cd ~/github
git clone git@github.com:datastax/cassandra-data-migrator.git
cd cassandra-data-migrator
mvn clean package
----

The fat jar (`cassandra-data-migrator-x.y.z.jar`) file should be present now in the `target` folder.

[[cdm-steps]]
== {cstar-data-migrator} steps

1. Configure for your environment the `cdm*.properties` file that's provided in the {cstar-data-migrator} https://github.com/datastax/cassandra-data-migrator/tree/main/src/resources[GitHub repo].
The file can have any name.
It does not need to be `cdm.properties` or `cdm-detailed.properties`.
In both versions, only the parameters that aren't commented out are processed with the `spark-submit` job.
Other parameter values use defaults or are ignored.
See the descriptions and defaults in each file.
Refer to:
   * The simplified sample properties configuration, https://github.com/datastax/cassandra-data-migrator/blob/main/src/resources/cdm.properties[cdm.properties].
   This file contains only those parameters that are commonly configured.
   * The complete sample properties configuration, https://github.com/datastax/cassandra-data-migrator/blob/main/src/resources/cdm-detailed.properties[cdm-detailed.properties], for the full set of configurable settings.

2. Place the properties file that you elected to use and customize where it can be accessed while running the job using `spark-submit`.

3. Run the job using `spark-submit` command:

[source,bash]
----
./spark-submit --properties-file cdm.properties \
--conf spark.cdm.schema.origin.keyspaceTable="<keyspacename>.<tablename>" \
--master "local[*]" --driver-memory 25G --executor-memory 25G \
--class com.datastax.cdm.job.Migrate cassandra-data-migrator-x.y.z.jar &> logfile_name_$(date +%Y%m%d_%H_%M).txt
----

[TIP]
====
* Above command generates a log file `logfile_name_*.txt` to avoid log output on the console.
* Update the memory options (driver & executor memory) based on your use-case
====

[[cdm-validation-steps]]
== {cstar-data-migrator} steps in validation mode

To run your migration job with {cstar-data-migrator} in **data validation mode**, use class option `--class com.datastax.cdm.job.DiffData`. 
Example:

[source,bash]
----
./spark-submit --properties-file cdm.properties \
--conf spark.cdm.schema.origin.keyspaceTable="<keyspacename>.<tablename>" \
--master "local[*]" --driver-memory 25G --executor-memory 25G \
--class com.datastax.cdm.job.DiffData cassandra-data-migrator-x.y.z.jar &> logfile_name_$(date +%Y%m%d_%H_%M).txt
----

The {cstar-data-migrator} validation job reports differences as `ERROR` entries in the log file. 
Example:

[source,bash]
----
23/04/06 08:43:06 ERROR DiffJobSession: Mismatch row found for key: [key3] Mismatch: Target Index: 1 Origin: valueC Target: value999) 
23/04/06 08:43:06 ERROR DiffJobSession: Corrected mismatch row in target: [key3]
23/04/06 08:43:06 ERROR DiffJobSession: Missing target row found for key: [key2]
23/04/06 08:43:06 ERROR DiffJobSession: Inserted missing row in target: [key2]
----

[TIP]
====
To get the list of missing or mismatched records, grep for all `ERROR` entries in the log files.
Differences noted in the log file are listed by primary-key values.
====

You can also run the {cstar-data-migrator} validation job in an **AutoCorrect** mode. This mode can:

* Add any missing records from the Origin to Target cluster.
* Update any mismatched records between Origin and Target; this action makes Target the same as Origin.

To enable or disable this feature, use one or both of the following settings in your `*.properties` configuration file.

[source,properties]
----
spark.cdm.autocorrect.missing                     false|true
spark.cdm.autocorrect.mismatch                    false|true
----

[IMPORTANT]
====
You may still have differences in your clusters after running validation job as {cstar-data-migrator} does not delete records from Target that don't exists on Origin.
The job only adds or updates records on the Target cluster that exists on the Origin cluster.
====

[[cdm--partition-ranges]]
== Migrating or validating specific partition ranges

You can also use {cstar-data-migrator} to migrate or validate specific partition ranges, by using a **partition-file** with the name `./<keyspacename>.<tablename>_partitions.csv`.
Use the following format in the CSV file, in the current folder as input. 
Example:

[source,csv]
----
-507900353496146534,-107285462027022883
-506781526266485690,1506166634797362039
2637884402540451982,4638499294009575633
798869613692279889,8699484505161403540
----

Each line in the CSV represents a partition-range (`min,max`). 

Alternatively, you can also pass the partition-file with a command-line parameter. 
Example:

[source,bash]
----
./spark-submit --properties-file cdm.properties \
 --conf spark.cdm.schema.origin.keyspaceTable="<keyspacename>.<tablename>" \
 --conf spark.cdm.tokenrange.partitionFile.input="/<path-to-file>/<csv-input-filename>" \
 --master "local[*]" --driver-memory 25G --executor-memory 25G \
 --class com.datastax.cdm.job.<Migrate|DiffData> cassandra-data-migrator-x.y.z.jar &> logfile_name_$(date +%Y%m%d_%H_%M).txt
----

This mode is specifically useful to processes a subset of partition-ranges that may have failed during a previous run.

[NOTE]
====
A file named `./<keyspacename>.<tablename>_partitions.csv` is auto-generated by the migration and validation jobs, in the format shown above.
The file contains any failed partition ranges.
No file is created if there were no failed partitions.
You can use the CSV as input to process any failed partition in a subsequent run.
====

[[cdm-guardrail-checks]]
== Perform large-field guardrail violation checks

Use {cstar-data-migrator} to identify large fields from a table that may break your cluster guardrails.
For example, {astra_db} has a 10MB limit for a single large field.
Specify `--class com.datastax.cdm.job.GuardrailCheck` on the command.
Example:

[source,bash]
----
./spark-submit --properties-file cdm.properties \
--conf spark.cdm.schema.origin.keyspaceTable="<keyspacename>.<tablename>" \
--conf spark.cdm.feature.guardrail.colSizeInKB=10000 \
--master "local[*]" --driver-memory 25G --executor-memory 25G \
--class com.datastax.cdm.job.GuardrailCheck cassandra-data-migrator-4.x.x.jar &> logfile_name_$(date +%Y%m%d_%H_%M).txt
----

[[cdm-reference]]
== {cstar-data-migrator} reference

* xref:cdm-parameters.adoc#cdm-connection-params[Common connection parameters for Origin and Target]
* xref:cdm-parameters.adoc#cdm-origin-schema-params[Origin schema parameters]
* xref:cdm-parameters.adoc#cdm-target-schema-params[Target schema parameter]
* xref:cdm-parameters.adoc#cdm-auto-correction-params[Auto-correction parameters]
* xref:cdm-parameters.adoc#cdm-performance-operations-params[Performance and operations parameters]
* xref:cdm-parameters.adoc#cdm-transformation-params[Transformation parameters]
* xref:cdm-parameters.adoc#cdm-cassandra-filter-params[Cassandra filter parameters]
* xref:cdm-parameters.adoc#cdm-java-filter-params[Java filter parameters]
* xref:cdm-parameters.adoc#cdm-constant-column-feature-params[Constant column feature parameters]
* xref:cdm-parameters.adoc#cdm-explode-map-feature-params[Explode map feature parameters]
* xref:cdm-parameters.adoc#cdm-guardrail-feature-params[Guardrail feature parameters]
* xref:cdm-parameters.adoc#cdm-tls-ssl-connection-params[TLS (SSL) connection parameters]
