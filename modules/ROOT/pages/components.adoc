= Compare {company} migration tools
:navtitle: Compare migration tools
:description: Learn about {company} migration tools.
:page-tag: migration,zdm,zero-downtime,zdm-proxy,components

{company} migration tools include the {product} {product-short} toolkit and three data migration tools.

{product-short} is comprised of {product-proxy}, {product-utility}, and {product-automation}, which orchestrate activity-in-transition on your clusters.
To move and validate data, you use {sstable-sideloader}, {cass-migrator}, or {dsbulk-migrator}.

You can also use {sstable-sideloader}, {cass-migrator-short}, and {dsbulk-migrator} on their own, outside the context of {product-short}.

== {product-proxy}

The main component of the {company} {product} toolkit is {product-proxy}, which is designed to be a lightweight proxy that handles all real-time requests generated by your client applications during the migration process.

{product-proxy} is open-source software that is available from the {product-proxy-repo}[zdm-proxy GitHub repo].
This project is open for public contributions.

The {product-proxy} is an orchestrator for monitoring application activity and keeping multiple clusters (databases) in sync through dual writes.
{product-proxy} isn't linked to the actual migration process.
It doesn't perform data migrations and it doesn't have awareness of ongoing migrations.
Instead, you use a data migration tool, like {sstable-sideloader}, {cass-migrator}, or {dsbulk-migrator}, to perform the data migration and validate migrated data.

{product-proxy} reduces risks to upgrades and migrations by decoupling the origin cluster from the target cluster and maintaining consistency between both clusters.
You decide when you want to switch permanently to the target cluster.

After migration your data, migrating your application code can be as minimal as changing the connection string, depending on your client's compatibility with your origin and target clusters.

[#how-zdm-proxy-handles-reads-and-writes]
=== How {product-proxy} handles reads and writes

{company} created {product-proxy} to orchestrate requests between a client application and both the origin and target clusters.
These clusters can be any CQL-compatible data store, such as {cass-reg}, {dse}, and {astra-db}.

During the migration process, you designate one cluster as the _primary cluster_, which serves as the source of truth for reads.
For the majority of the migration process, this is typically the origin cluster.
Towards the end of the migration process, when you are ready to read from your target cluster, you set the target cluster as the primary cluster.

==== Writes

{product-proxy} sends every write operation (`INSERT`, `UPDATE`, `DELETE`) synchronously to both clusters at the requested consistency level:

* If the write is acknowledged in both clusters at the requested consistency level, then the operation returns a successful write acknowledgement to the client that issued the request.
* If the write fails in either cluster, then the primary cluster passes a write failure back to the client.
The client can then execute its retry policy and reissue the request, if applicable.

This design ensures that new data is always written to both clusters, and that any failure on either cluster is always made visible to the client application.

For information about how {product-proxy} handles lightweight transactions (LWTs), see xref:feasibility-checklists.adoc#_lightweight_transactions_and_the_applied_flag[Lightweight Transactions and the applied flag].

==== Reads

By default, {product-proxy} sends all reads to the primary cluster, and then returns the result to the client application.

//TODO: Compare Async Dual Writes content with enable-async-dual-reads.adoc.

Optionally, you can configure {product-proxy} to read asynchronously from both the origin and target clusters.
This is known as **Asynchronous Dual Reads** or **Read Mirroring**, and it allows you to test the target cluster's ability to handle a production workload.

* Results from the asynchronous reads executed on the target cluster aren't sent back to the client application.
* This design implies that a failure on asynchronous reads from the target cluster won't cause an error on the client application.
* With Asynchronous Dual Reads, the additional read load on the target cluster can impact its ability to execute writes.
This behavior is expected because this feature is designed to mimic the full read and write workload on the target cluster.
This allows you to judge the target cluster's performance and make any adjustments before permanently switching to the target cluster at the end of the migration process.

You can dynamically enable and disable Asynchronous Dual Reads by modifying the configuration of your {product-proxy} instances, and then performing a rolling restart of your {product-proxy} instances.
For more information, see xref:ROOT:enable-async-dual-reads.adoc[].

After enabling Asynchronous Dual Reads, observe the target cluster's read latency and throughput to determine how well the target cluster performs under the expected production workload.

=== High availability and multiple {product-proxy} instances

{product-proxy} is designed to be highly available and run a clustered fashion to avoid a single point of failure.

With the exception of local test environments, {company} recommends that all {product-proxy} deployments have multiple {product-proxy} instances.
Deployments typically consist of three or more instances.

[TIP]
====
Throughout the {product-short} documentation, the term _{product-proxy} deployment_ refers to the entire deployment, and _{product-proxy} instance_ refers to an individual proxy process in the deployment.
====

You can scale {product-proxy} instances horizontally and vertically.
To avoid downtime when applying configuration changes, you can perform rolling restarts on your {product-proxy} instances.

For simplicity, you can use the {product-utility} and {product-automation} to set up and run Ansible playbooks that deploy and manage {product-proxy} and its monitoring stack.

== {product-utility} and {product-automation}

You can use the {product-automation-repo}[{product-utility} and {product-automation}] to set up and run Ansible playbooks that deploy and manage {product-proxy} and its monitoring stack.

https://www.ansible.com/[Ansible] is a suite of software tools that enables infrastructure as code.
It is open source and its capabilities include software provisioning, configuration management, and application deployment functionality.
The Ansible automation for {product-short} is organized into playbooks, each implementing a specific operation.
The machine from which the playbooks are run is known as the Ansible Control Host.
In {product-short}, the Ansible Control Host runs as a Docker container.

You use the {product-utility} to set up Ansible in a Docker container, and then you use {product-automation} to run the Ansible playbooks from the Docker container created by {product-utility}.

The {product-utility} creates the Docker container acting as the Ansible Control Host, from which {product-automation} allows you to deploy and manage the {product-proxy} instances and the associated monitoring stack, which includes Prometheus metrics and Grafana visualizations of the metrics data.

To use {product-utility} and {product-automation}, you must prepare the recommended infrastructure, as explained in xref:deployment-infrastructure.adoc[].

For more information, see xref:setup-ansible-playbooks.adoc[] and xref:deploy-proxy-monitoring.adoc[].

include::ROOT:migrate-and-validate-data.adoc[tags=migration-tool-summaries]